# Neural Networks

![Popular Neural Network Architecture](https://cdn-images-1.medium.com/max/1600/0*AYTsMuWP7JdoLf78.jpg)

# Types of Neuran Networks

MLP, CNN, DCNN, RNN, and LSTM are all types of neural networks that are used in different applications for deep learning. Here's a brief comparison of these networks:

- MLP - Multilayer Perceptron <br/> 
MLP is a type of feedforward neural network that consists of an input layer, one or more hidden layers, and an output layer. Each layer is composed of several neurons that perform computations on the input data. MLPs are commonly used for classification and regression tasks.

- CNN - Convolutional Neural Networks <br/> 
CNNs are used primarily for image and video recognition tasks. They consist of multiple convolutional layers that extract features from the input data, followed by pooling layers that downsample the features. CNNs can learn spatial hierarchies of patterns in data and are highly effective at object recognition.

- DCNN - Deep Convolutional Neural Networks <br/> 
DCNNs are similar to CNNs, but they are deeper and have more layers. They are used for more complex image recognition tasks, such as image segmentation and object detection. DCNNs can learn spatial hierarchies of patterns in data and are highly effective at object recognition.

- RNN - Recurrent Neural Networks <br/> 
RNNs are used primarily for natural language processing and speech recognition tasks. They can handle variable-length input sequences and have a feedback mechanism that allows them to use information from previous steps to inform the current step. RNNs can learn sequential patterns in data and are highly effective at predicting the next word in a sentence or the next phoneme in a speech signal.

- LSTM - Long Short-Term Memory <br/>
LSTM is a type of RNN that is designed to handle the problem of vanishing gradients. It has a more complex architecture that allows it to selectively remember or forget information from previous steps. LSTMs are commonly used for speech recognition, language modeling, and video analysis.

- GANs - Generative Adversarial Networks <br/> 
GANs are a type of neural network that consists of two networks: a generator network that generates new data samples, and a discriminator network that tries to distinguish between the generated samples and real samples. The generator network learns to generate samples that are indistinguishable from real samples, while the discriminator network learns to correctly identify the real samples. GANs can be used for tasks such as image synthesis and data augmentation.

- Autoencoder <br/> 
An autoencoder is a type of neural network that is used for unsupervised learning. It consists of an encoder network that maps the input data to a lower-dimensional representation, and a decoder network that maps the lower-dimensional representation back to the original data. Autoencoders can be used for tasks such as data compression and denoising

In summary, MLPs are primarily used for classification and regression tasks, CNNs and DCNNs are primarily used for image recognition tasks, RNNs are primarily used for natural language processing and speech recognition tasks, and LSTMs are a type of RNN that is designed to handle long-term dependencies in sequential data.

# Posts
- [Convolutional Neural Networks](http://cs231n.github.io/convolutional-networks/)

# Slides
- [Slides](https://www.slideshare.net/akashmaurya24/14-mohsin-dalvi-artificial-neural-networks-presentation)

# Books:

- [Neural Networks and Deep Learning](http://neuralnetworksanddeeplearning.com/chap1.html)

# Videos

- [AI - Giorgi Koguashvili](https://www.youtube.com/playlist?list=PL2XGvKfYRbDt7AUAMAhctVC9SZsGknyFp)
- [Neural networks - 3Blue1Brown](https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi)

# Repos

- [:octocat:](https://github.com/demidovakatya/vvedenie-mashinnoe-obuchenie/blob/master/neural-nets.md)
